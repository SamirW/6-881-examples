{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from plan_runner.environment import ManipStationEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import utils\n",
    "from sac import SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs policy for X episodes and returns average reward\n",
    "def evaluate_policy(agent, eval_episodes=10, max_action=max_action):\n",
    "    avg_reward = 0.\n",
    "    for i in xrange(eval_episodes):\n",
    "        print(\"Test {}\".format(i))\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.select_action(np.array(obs), eval=True)\n",
    "            action = max_action*np.tanh(action)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            avg_reward += reward\n",
    "\n",
    "    avg_reward /= eval_episodes\n",
    "\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Evaluation over %d episodes: %f\" % (eval_episodes, avg_reward))\n",
    "    print(\"---------------------------------------\")\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this to visualize policies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 0\n",
    "num_evals = 10\n",
    "visualize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "parser.add_argument('--env-name', default=\"HalfCheetah-v2\",\n",
    "                    help='name of the environment to run')\n",
    "parser.add_argument('--policy', default=\"Gaussian\",\n",
    "                    help='algorithm to use: Gaussian | Deterministic')\n",
    "parser.add_argument('--eval', type=bool, default=False,\n",
    "                    help='Evaluate a policy (default:False)')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor for reward (default: 0.99)')\n",
    "parser.add_argument('--tau', type=float, default=0.005, metavar='G',\n",
    "                    help='target smoothing coefficient(tau) (default: 0.005)')\n",
    "parser.add_argument('--lr', type=float, default=0.0003, metavar='G',\n",
    "                    help='learning rate (default: 0.0003)')\n",
    "parser.add_argument('--alpha', type=float, default=0.2, metavar='G',\n",
    "                    help='Temperature parameter alpha determines the relative importance of the entropy term against the reward (default: 0.2)')\n",
    "parser.add_argument('--seed', type=int, default=543, metavar='N',\n",
    "                    help='random seed (default: 543)')\n",
    "parser.add_argument('--batch_size', type=int, default=256, metavar='N',\n",
    "                    help='batch size (default: 256)')\n",
    "parser.add_argument('--num_steps', type=int, default=1000000, metavar='N',\n",
    "                    help='maximum number of steps (default: 1000000)')\n",
    "parser.add_argument('--hidden_size', type=int, default=256, metavar='N',\n",
    "                    help='hidden size (default: 256)')\n",
    "parser.add_argument('--updates_per_step', type=int, default=1, metavar='N',\n",
    "                    help='model updates per simulator step (default: 1)')\n",
    "parser.add_argument('--target_update_interval', type=int, default=1, metavar='N',\n",
    "                    help='Value target update per no. of updates per step (default: 1)')\n",
    "parser.add_argument('--replay_size', type=int, default=1000000, metavar='N',\n",
    "                    help='size of replay buffer (default: 10000000)')\n",
    "parser.add_argument('--save_freq', type=int, default=15000,\n",
    "                    help='how often to save model and rewards')\n",
    "parser.add_argument('--load', action='store_true',\n",
    "                    help='load from previous model')\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(\"--seed 5 --alpha 0.05\".split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Settings: SAC_ManipStation_5\n",
      "---------------------------------------\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Setting up visualizer...\n",
      "Loading models from models/sac_actor_5, models/sac_critic_5 and models/sac_value_5\n",
      "Starting in 3 seconds...\n",
      "2...\n",
      "1...\n",
      "Starting!\n",
      "Test 0\n",
      "Test 1\n",
      "Resetting\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Setting up visualizer...\n",
      "Test 2\n",
      "Resetting\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Setting up visualizer...\n",
      "Test 3\n",
      "Resetting\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Setting up visualizer...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c0545d3b0fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mevaluate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-eab15b337252>\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(agent, eval_episodes)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/6-881-examples/plan_runner/environment.pyc\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_sim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resetting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_time_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_time_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_visualizing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_visualizing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/6-881-examples/plan_runner/environment.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, real_time_rate, is_visualizing)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Setting up visualizer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Construct Simulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_name = \"SAC\"\n",
    "env_name = \"ManipStation\"\n",
    "\n",
    "file_name = \"%s_%s_%s\" % (policy_name, env_name, str(args.seed))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Settings: %s\" % (file_name))\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "if not os.path.exists(\"./results\"):\n",
    "    exit()\n",
    "\n",
    "env = ManipStationEnvironment(is_visualizing=visualize)\n",
    "\n",
    "# Set seeds\n",
    "env.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "state_dim = env.state_dim\n",
    "action_space = env.action_space\n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "agent = SAC(state_dim, action_space, max_action, args)\n",
    "actor_path = 'models/sac_actor_{}'.format(args.seed)\n",
    "critic_path = 'models/sac_critic_{}'.format(args.seed)\n",
    "value_path = 'models/sac_value_{}'.format(args.seed)\n",
    "agent.load_model(actor_path=actor_path,\n",
    "    critic_path=critic_path,\n",
    "    value_path=value_path)\n",
    "\n",
    "print(\"Starting in 3 seconds...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "time.sleep(1)\n",
    "print(\"Starting!\")\n",
    "\n",
    "evaluate_policy(agent, eval_episodes=num_evals, max_action=max_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this for charts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data_set, periods=10):\n",
    "    weights = np.ones(periods) / periods\n",
    "    return np.convolve(data_set, weights, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as plot\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "params = {'legend.fontsize': 12}\n",
    "plot.rcParams.update(params)\n",
    "\n",
    "BASE_DIR = '/home/samir/Documents/6881/final_project/models/'\n",
    "FIGURE_NAME = 'figures/test.png'\n",
    "\n",
    "CONV_SIZE = 100\n",
    "NUM_SEEDS = 10\n",
    "\n",
    "SHOW = True\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "datas_x = []\n",
    "\n",
    "for i in range(NUM_SEEDS):\n",
    "    path = \\\n",
    "        BASE_DIR + \\\n",
    "        \"results_{}.npy\".format(i+1)\n",
    "\n",
    "    try:\n",
    "        data = np.load(path)\n",
    "        print(data)\n",
    "        clean_data = data[np.where(data !=0)]\n",
    "        clean_data = clean_data[np.where(clean_data > -500)]\n",
    "        \n",
    "        avg_data = moving_average(clean_data, CONV_SIZE)\n",
    "        \n",
    "        data_x = np.arange(len(clean_data)) + 1\n",
    "        data_x = moving_average(data_x, CONV_SIZE)\n",
    "        \n",
    "        datas.append(avg_data)\n",
    "        datas_x.append(data_x)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "num = 12750\n",
    "new_data = []\n",
    "for i, d in enumerate(datas):\n",
    "    new_data.append(d[:num])\n",
    "    datas_x[i] = datas_x[i][:num]\n",
    "print(datas)\n",
    "print(datas_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b08261f0b236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ticks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatas_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set_style(\"ticks\")\n",
    "data = new_data\n",
    "x = datas_x[0]\n",
    "mean = np.mean(data, axis=0)\n",
    "std = np.std(data, axis=0)\n",
    "error = (mean - std, mean + std)\n",
    "\n",
    "ax.fill_between(x, error[0], error[1], alpha=0.2)\n",
    "ax.plot(x, mean, label='')\n",
    "ax.margins(x=0)\n",
    "\n",
    "plt.xlabel(r'\\textbf{Train Episode}', size=14)\n",
    "plt.ylabel(r'\\textbf{Training Reward}', size=14)\n",
    "plt.title(r'\\textbf{TD3 - Reach Fixed Location}', size=15)\n",
    "\n",
    "# legend = plt.legend(\n",
    "#     bbox_to_anchor=(0., 1.07, 1., .102), \n",
    "#     loc=3, \n",
    "#     ncol=2, \n",
    "#     mode=\"expand\", \n",
    "#     borderaxespad=0.)\n",
    "\n",
    "if SAVE:\n",
    "    \n",
    "    plt.savefig(BASE_DIR + FIGURE_NAME, bbox_inches=\"tight\", dpi=300) \n",
    "\n",
    "if SHOW:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
